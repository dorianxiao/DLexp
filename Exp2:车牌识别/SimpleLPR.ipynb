{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleLPR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorianxiao/DLexp/blob/master/Exp2%3A%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/SimpleLPR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMGUk41x4lMw",
        "colab_type": "text"
      },
      "source": [
        "# 0. 导入相关库"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvmO-zrh4dbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 导入相关库\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9NJrfw26KgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7bcf5c62-64e6-4918-f138-ffc18b3db336"
      },
      "source": [
        "# 挂载到Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpXUOO2l5IKn",
        "colab_type": "text"
      },
      "source": [
        "# 1. 地区识别，其他类似不再赘述"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBUH90zh7XH_",
        "colab_type": "text"
      },
      "source": [
        "## 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smsUj3334_jO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义全局变量\n",
        "\n",
        "SIZE = 400\n",
        "WIDTH = 20\n",
        "HEIGHT = 20\n",
        "NUM_CLASSES = 26\n",
        "iterations = 500\n",
        " \n",
        "SAVER_DIR = r'/content/gdrive/My Drive/mylab/Exp2/train-saver/letters/'\n",
        " \n",
        "LETTERS_DIGITS = (\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\")\n",
        "\n",
        "license_num = \"\"\n",
        "\n",
        "time_begin = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgBihpU94wA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义输入节点，对应于图片像素值矩阵集合和图片标签(即所代表的数字)\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[None, SIZE])\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, NUM_CLASSES])\n",
        " \n",
        "x_image = tf.reshape(x, [-1, WIDTH, HEIGHT, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWJPg3i45cjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 训练集\n",
        "# 第一次遍历图片目录是为了获取图片总数\n",
        "input_count = 0\n",
        "for i in range(0,NUM_CLASSES):\n",
        "    dir = r'/content/gdrive/My Drive/mylab/Exp2/dataset/train/area/%s/' % i\t# i为分类标签\n",
        "    for rt, dirs, files in os.walk(dir):\n",
        "        for filename in files:\n",
        "            input_count += 1\n",
        "\n",
        "# 定义对应维数和各维长度的数组(初始化为0)\n",
        "# 输入图片数组尺寸为 input_count*400\n",
        "input_images = np.array([[0]*SIZE for i in range(input_count)])\n",
        "# 输入图片标签数组尺寸为 input_count*26\n",
        "input_labels = np.array([[0]*NUM_CLASSES for i in range(input_count)])\n",
        "\n",
        "# 第二次遍历图片目录是为了生成图片数据和标签\n",
        "index = 0\n",
        "for i in range(0,NUM_CLASSES):\n",
        "    dir = r'/content/gdrive/My Drive/mylab/Exp2/dataset/train/area/%s/' % i\n",
        "    for rt, dirs, files in os.walk(dir):\n",
        "        for filename in files:\n",
        "            filename = dir + filename\n",
        "            img = Image.open(filename)\n",
        "            width = img.size[0]\n",
        "            height = img.size[1]\n",
        "            for h in range(0, height):\n",
        "                for w in range(0, width):\n",
        "                    input_images[index][w+h*width] = img.getpixel((w,h))\n",
        "            input_labels[index][i] = 1\n",
        "            index += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc4Y5XMG5uHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 验证集\n",
        "# 第一次遍历图片目录是为了获取图片总数\n",
        "val_count = 0\n",
        "for i in range(0,NUM_CLASSES):\n",
        "    dir = r'/content/gdrive/My Drive/mylab/Exp2/dataset/val/area/%s/' % i\n",
        "    for rt, dirs, files in os.walk(dir):\n",
        "        for filename in files:\n",
        "            val_count += 1\n",
        "\n",
        "# 定义对应维数和各维长度的数组\n",
        "val_images = np.array([[0]*SIZE for i in range(val_count)])\n",
        "val_labels = np.array([[0]*NUM_CLASSES for i in range(val_count)])\n",
        "\n",
        "# 第二次遍历图片目录是为了生成图片数据和标签\n",
        "index = 0\n",
        "for i in range(0,NUM_CLASSES):\n",
        "    dir = r'/content/gdrive/My Drive/mylab/Exp2/dataset/val/area/%s/' % i\n",
        "    for rt, dirs, files in os.walk(dir):\n",
        "        for filename in files:\n",
        "            filename = dir + filename\n",
        "            img = Image.open(filename)\n",
        "            width = img.size[0]\n",
        "            height = img.size[1]\n",
        "            for h in range(0, height):\n",
        "                for w in range(0, width):\n",
        "                    val_images[index][w+h*width] = img.getpixel((w, h))\n",
        "            val_labels[index][i] = 1\n",
        "            index += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8ck8IO56nnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义卷积函数\n",
        "def conv_layer(inputs, W, b, conv_strides, kernel_size, pool_strides, padding):\n",
        "    L1_conv = tf.nn.conv2d(inputs, W, strides=conv_strides, padding=padding)\n",
        "    L1_relu = tf.nn.relu(L1_conv + b)\n",
        "    return tf.nn.max_pool(L1_relu, ksize=kernel_size, strides=pool_strides, padding='SAME')\n",
        "\n",
        "# 定义全连接层函数\n",
        "def full_connect(inputs, W, b):\n",
        "    return tf.nn.relu(tf.matmul(inputs, W) + b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NraEEJxq6aFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4474
        },
        "outputId": "db0c7e12-766e-46a4-c6d2-898d8230aacc"
      },
      "source": [
        "# 创建会话\n",
        "with tf.Session() as sess:\n",
        "    # 第一个卷积层\n",
        "    W_conv1 = tf.Variable(tf.truncated_normal([3, 3, 1, 16], stddev=0.1), name=\"W_conv1\")\n",
        "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[16]), name=\"b_conv1\")\n",
        "    conv_strides = [1, 1, 1, 1]\n",
        "    kernel_size = [1, 2, 2, 1]\n",
        "    pool_strides = [1, 2, 2, 1]\n",
        "    L1_pool = conv_layer(x_image, W_conv1, b_conv1, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
        "\n",
        "    # 第二个卷积层\n",
        "    W_conv2 = tf.Variable(tf.truncated_normal([3, 3, 16, 32], stddev=0.1), name=\"W_conv2\")\n",
        "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[32]), name=\"b_conv2\")\n",
        "    conv_strides = [1, 1, 1, 1]\n",
        "    kernel_size = [1, 1, 1, 1]\n",
        "    pool_strides = [1, 1, 1, 1]\n",
        "    L2_pool = conv_layer(L1_pool, W_conv2, b_conv2, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
        "\n",
        "\n",
        "    # 全连接层\n",
        "    W_fc1 = tf.Variable(tf.truncated_normal([10 * 10 * 32, 512], stddev=0.1), name=\"W_fc1\")\n",
        "    b_fc1 = tf.Variable(tf.constant(0.1, shape=[512]), name=\"b_fc1\")\n",
        "    h_pool2_flat = tf.reshape(L2_pool, [-1, 10 * 10 * 32])\n",
        "    h_fc1 = full_connect(h_pool2_flat, W_fc1, b_fc1)\n",
        "\n",
        "\n",
        "    # dropout\n",
        "    keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "\n",
        "\n",
        "    # readout层\n",
        "    W_fc2 = tf.Variable(tf.truncated_normal([512, NUM_CLASSES], stddev=0.1), name=\"W_fc2\")\n",
        "    b_fc2 = tf.Variable(tf.constant(0.1, shape=[NUM_CLASSES]), name=\"b_fc2\")\n",
        "\n",
        "    # 定义优化器和训练op\n",
        "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
        "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
        "    train_step = tf.train.AdamOptimizer((1e-4)).minimize(cross_entropy)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    time_elapsed = time.time() - time_begin\n",
        "    print(\"读取图片文件耗费时间：%d秒\" % time_elapsed)\n",
        "    time_begin = time.time()\n",
        "\n",
        "    print (\"一共读取了 %s 个训练图像， %s 个标签\" % (input_count, input_count))\n",
        "    print (\"一共读取了 %s 个验证图像， %s 个标签\" % (val_count, val_count))\n",
        "\n",
        "    print (\"train shape:\", (input_images.shape))\n",
        "    print (\"val shape:\", (val_images.shape))\n",
        "\n",
        "    # 设置每次训练op的输入个数和迭代次数，这里为了支持任意图片总数，定义了一个余数remainder，譬如，如果每次训练op的输入个数为60，图片总数为150张，则前面两次各输入60张，最后一次输入30张（余数30）\n",
        "    batch_size = 60\n",
        "    iterations = iterations\n",
        "    batches_count = int(input_count / batch_size)\n",
        "    remainder = input_count % batch_size\n",
        "    print (\"训练数据集分成 %s 批, 前面每批 %s 个数据，最后一批 %s 个数据\" % (batches_count+1, batch_size, remainder))\n",
        "    print(input_images.shape)\n",
        "    print(val_images.shape)\n",
        "    input_images.reshape((-1, 20*20))\n",
        "    val_images.reshape((-1, 20*20))\n",
        "\n",
        "    input_images = input_images.astype(\"float32\")/255\n",
        "    val_images = val_images.astype(\"float32\")/255\n",
        "    testimg = np.reshape(input_images[0], (-1, 20*20))\n",
        "    print(testimg)\n",
        "    testimg = np.reshape(val_images[0], (-1, 20*20))\n",
        "    print(testimg)\n",
        "    print(input_images.shape)\n",
        "    print(val_images.shape)\n",
        "\n",
        "    # 执行训练迭代\n",
        "    for it in range(iterations):\n",
        "        # 这里的关键是要把输入数组转为np.array\n",
        "        for n in range(batches_count):\n",
        "            train_step.run(feed_dict={x: input_images[n*batch_size:(n+1)*batch_size], y_: input_labels[n*batch_size:(n+1)*batch_size], keep_prob: 0.5})\n",
        "        if remainder > 0:\n",
        "            start_index = batches_count * batch_size;\n",
        "            train_step.run(feed_dict={x: input_images[start_index:input_count-1], y_: input_labels[start_index:input_count-1], keep_prob: 0.5})\n",
        "\n",
        "        # 每完成五次迭代，判断准确度是否已达到100%，达到则退出迭代循环\n",
        "        iterate_accuracy = 0\n",
        "        if it%5 == 0:\n",
        "            train_accuracy = accuracy.eval(feed_dict={x: input_images, y_: input_labels, keep_prob: 1.0})\n",
        "            iterate_accuracy = accuracy.eval(feed_dict={x: val_images, y_: val_labels, keep_prob: 1.0})\n",
        "            print ('第 %d 次训练迭代: train准确率 %0.5f%%, val准确率 %0.5f%%' % (it, train_accuracy*100, iterate_accuracy*100))\n",
        "            if iterate_accuracy >= 0.9999 and it >= iterations:\n",
        "                break;\n",
        "\n",
        "    print ('完成训练!')\n",
        "    time_elapsed = time.time() - time_begin\n",
        "    print (\"训练耗费时间：%d秒\" % time_elapsed)\n",
        "    time_begin = time.time()\n",
        "\n",
        "    # 保存训练结果\n",
        "    if not os.path.exists(SAVER_DIR):\n",
        "        print ('不存在训练数据保存目录，现在创建保存目录')\n",
        "        os.makedirs(SAVER_DIR)\n",
        "    # 初始化saver\n",
        "    saver = tf.train.Saver()            \n",
        "    saver_path = saver.save(sess, \"%smodel.ckpt\"%(SAVER_DIR))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-8-7d0d94e039e1>:29: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From <ipython-input-8-7d0d94e039e1>:38: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "读取图片文件耗费时间：3059秒\n",
            "一共读取了 6713 个训练图像， 6713 个标签\n",
            "一共读取了 3467 个验证图像， 3467 个标签\n",
            "train shape: (6713, 400)\n",
            "val shape: (3467, 400)\n",
            "训练数据集分成 112 批, 前面每批 60 个数据，最后一批 53 个数据\n",
            "(6713, 400)\n",
            "(3467, 400)\n",
            "[[0.         0.         0.00392157 0.00784314 0.00784314 0.\n",
            "  0.00392157 0.00392157 0.23529412 1.         1.         0.1254902\n",
            "  0.         0.01176471 0.         0.00784314 0.         0.\n",
            "  0.         0.         0.         0.00392157 0.00784314 0.00784314\n",
            "  0.         0.01176471 0.         0.00392157 0.9843137  0.99215686\n",
            "  1.         0.12941177 0.         0.01568628 0.00784314 0.00784314\n",
            "  0.         0.         0.         0.         0.01176471 0.01568628\n",
            "  0.         0.         0.         0.01568628 0.00392157 0.\n",
            "  1.         0.96862745 0.98039216 0.13333334 0.         0.\n",
            "  0.01568628 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.01568628 0.01176471 0.01176471 0.\n",
            "  0.00392157 0.7764706  0.972549   1.         1.         0.88235295\n",
            "  0.00392157 0.00392157 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.00392157 0.00392157 0.         0.\n",
            "  0.01568628 0.         0.         0.88235295 1.         0.99607843\n",
            "  0.99607843 1.         0.         0.         0.00784314 0.\n",
            "  0.         0.         0.         0.         0.01176471 0.\n",
            "  0.00784314 0.01960784 0.00392157 0.         0.02352941 0.8745098\n",
            "  0.99607843 1.         0.98039216 1.         0.         0.\n",
            "  0.01176471 0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.02352941 0.         0.         0.01960784\n",
            "  0.         0.8784314  1.         0.9882353  1.         0.98039216\n",
            "  0.01176471 0.         0.         0.01960784 0.         0.\n",
            "  0.         0.         0.00392157 0.         0.00784314 0.00784314\n",
            "  0.         0.00392157 0.54901963 0.9843137  0.99215686 1.\n",
            "  0.99215686 0.99607843 0.75686276 0.         0.01176471 0.\n",
            "  0.         0.         0.         0.         0.         0.01176471\n",
            "  0.00784314 0.         0.01960784 0.00392157 0.61960787 0.99607843\n",
            "  0.9843137  0.88235295 0.95686275 0.99215686 0.88235295 0.00784314\n",
            "  0.         0.00784314 0.         0.         0.         0.\n",
            "  0.01176471 0.         0.00784314 0.01568628 0.00392157 0.\n",
            "  0.62352943 1.         0.8666667  0.01176471 0.62352943 0.99607843\n",
            "  0.8862745  0.         0.00392157 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.01960784 0.         0.00392157\n",
            "  0.         0.01176471 0.60784316 1.         0.8862745  0.00784314\n",
            "  0.23921569 0.92156863 0.9490196  0.39215687 0.         0.\n",
            "  0.         0.         0.         0.         0.01176471 0.00392157\n",
            "  0.00784314 0.         0.         0.3254902  0.95686275 0.9882353\n",
            "  0.88235295 0.         0.01176471 0.8901961  0.99607843 0.627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.         0.37254903\n",
            "  1.         1.         0.         0.02745098 0.         0.8745098\n",
            "  1.         0.6156863  0.00784314 0.         0.         0.\n",
            "  0.         0.         0.00784314 0.00784314 0.00392157 0.00784314\n",
            "  0.         0.38039216 1.         1.         0.00784314 0.00392157\n",
            "  0.22745098 0.9372549  1.         0.61960787 0.         0.01176471\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.         0.38431373 1.         0.99607843\n",
            "  0.6        0.6313726  0.8666667  0.99607843 0.99607843 0.85490197\n",
            "  0.24313726 0.         0.         0.         0.         0.\n",
            "  0.00392157 0.00392157 0.         0.00784314 0.00392157 0.3764706\n",
            "  0.9882353  0.99607843 1.         0.99215686 0.99607843 1.\n",
            "  0.9882353  1.         0.36078432 0.         0.         0.\n",
            "  0.         0.         0.         0.00784314 0.00392157 0.\n",
            "  0.13333334 0.99607843 0.99607843 1.         0.8745098  0.8627451\n",
            "  0.8784314  0.99607843 1.         0.9882353  0.45490196 0.02352941\n",
            "  0.         0.         0.         0.         0.00784314 0.01960784\n",
            "  0.         0.         0.10588235 1.         0.9843137  0.6666667\n",
            "  0.00392157 0.01960784 0.         0.53333336 0.99607843 0.99215686\n",
            "  1.         0.13333334 0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.         0.6901961  0.9843137\n",
            "  1.         0.12941177 0.         0.01960784 0.         0.00392157\n",
            "  0.45882353 0.9882353  0.99215686 0.09803922 0.         0.\n",
            "  0.         0.         0.00784314 0.         0.         0.02352941\n",
            "  0.25490198 0.96862745 0.45882353 0.         0.02352941 0.\n",
            "  0.01176471 0.         0.13333334 0.99607843 0.4627451  0.05098039\n",
            "  0.         0.         0.         0.        ]]\n",
            "[[0.01960784 0.         0.00784314 0.         0.         0.00784314\n",
            "  0.         0.00784314 0.         0.00392157 0.00784314 0.\n",
            "  0.00784314 0.         0.01176471 0.         0.         0.\n",
            "  0.         0.         0.         0.01568628 0.00392157 0.\n",
            "  0.01176471 0.00784314 0.         0.         0.00784314 0.00392157\n",
            "  0.22352941 0.2        0.10196079 0.         0.         0.00784314\n",
            "  0.         0.         0.         0.         0.01176471 0.00392157\n",
            "  0.         0.         0.         0.00784314 0.         0.03529412\n",
            "  0.14117648 0.5686275  0.73333335 0.8980392  0.5568628  0.08235294\n",
            "  0.         0.00392157 0.         0.         0.         0.\n",
            "  0.         0.         0.00392157 0.01176471 0.         0.02352941\n",
            "  0.         0.13333334 0.5568628  0.9490196  1.         0.9254902\n",
            "  0.4627451  0.03529412 0.         0.00392157 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.01960784\n",
            "  0.01176471 0.         0.21176471 0.69803923 0.9882353  0.98039216\n",
            "  0.99607843 0.9647059  0.57254905 0.09803922 0.01176471 0.00784314\n",
            "  0.         0.         0.         0.         0.         0.01568628\n",
            "  0.         0.         0.01176471 0.07843138 0.52156866 0.9529412\n",
            "  0.99607843 1.         1.         0.92156863 0.47843137 0.0627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.00784314 0.00784314 0.         0.20784314\n",
            "  0.75686276 0.9882353  1.         1.         0.99607843 0.9882353\n",
            "  0.5921569  0.08235294 0.02352941 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.         0.00784314 0.00392157\n",
            "  0.         0.36078432 0.8980392  0.9882353  1.         1.\n",
            "  0.99607843 0.99607843 0.7137255  0.2        0.00784314 0.00392157\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.01568628 0.02745098 0.49019608 0.95686275 1.\n",
            "  0.9372549  0.6431373  0.8235294  0.9882353  0.8352941  0.2627451\n",
            "  0.01960784 0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.00784314 0.         0.17254902 0.6627451\n",
            "  0.98039216 0.9411765  0.5137255  0.22352941 0.7254902  0.9764706\n",
            "  0.8509804  0.30588236 0.01568628 0.01568628 0.         0.\n",
            "  0.         0.         0.00784314 0.01176471 0.         0.01568628\n",
            "  0.30588236 0.8627451  1.         0.8745098  0.2901961  0.01960784\n",
            "  0.64705884 1.         0.9607843  0.62352943 0.1254902  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00784314 0.03529412 0.4392157  0.9254902  0.972549   0.69803923\n",
            "  0.1764706  0.04313726 0.49803922 0.9647059  0.9843137  0.67058825\n",
            "  0.13725491 0.01176471 0.         0.         0.         0.\n",
            "  0.02352941 0.00784314 0.01960784 0.1764706  0.6509804  0.972549\n",
            "  0.9647059  0.6901961  0.2627451  0.27450982 0.70980394 0.9882353\n",
            "  0.96862745 0.76862746 0.25882354 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.00392157 0.08235294 0.46666667\n",
            "  0.8862745  0.9882353  1.         0.9882353  0.9647059  0.9411765\n",
            "  0.9882353  0.99607843 1.         0.8745098  0.37254903 0.01176471\n",
            "  0.         0.         0.         0.         0.00784314 0.00784314\n",
            "  0.05882353 0.3764706  0.84705883 1.         0.9843137  0.90588236\n",
            "  0.84705883 0.84313726 0.88235295 0.9843137  1.         0.92941177\n",
            "  0.50980395 0.09411765 0.         0.         0.         0.\n",
            "  0.00784314 0.         0.13333334 0.6        0.93333334 0.8666667\n",
            "  0.44313726 0.13725491 0.02745098 0.03529412 0.16862746 0.6666667\n",
            "  0.9529412  0.99215686 0.75686276 0.20784314 0.         0.\n",
            "  0.         0.         0.         0.01176471 0.17254902 0.6156863\n",
            "  0.84313726 0.56078434 0.11372549 0.00392157 0.00784314 0.\n",
            "  0.03137255 0.2901961  0.7490196  0.93333334 0.7764706  0.27058825\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.08235294 0.11764706 0.08235294 0.         0.\n",
            "  0.00392157 0.         0.00392157 0.02352941 0.14509805 0.21960784\n",
            "  0.18431373 0.01960784 0.         0.         0.         0.\n",
            "  0.01960784 0.         0.         0.00784314 0.         0.\n",
            "  0.00784314 0.00392157 0.00392157 0.         0.02352941 0.00784314\n",
            "  0.         0.01568628 0.         0.00784314 0.         0.\n",
            "  0.         0.         0.         0.         0.00392157 0.\n",
            "  0.00784314 0.00392157 0.00784314 0.         0.01176471 0.01176471\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.         0.         0.        ]]\n",
            "(6713, 400)\n",
            "(3467, 400)\n",
            "第 0 次训练迭代: train准确率 16.86280%, val准确率 6.14364%\n",
            "第 5 次训练迭代: train准确率 65.81260%, val准确率 32.53533%\n",
            "第 10 次训练迭代: train准确率 91.62818%, val准确率 63.10931%\n",
            "第 15 次训练迭代: train准确率 95.75450%, val准确率 73.49293%\n",
            "第 20 次训练迭代: train准确率 95.94816%, val准确率 75.71387%\n",
            "第 25 次训练迭代: train准确率 96.11202%, val准确率 77.41563%\n",
            "第 30 次训练迭代: train准确率 96.96112%, val准确率 77.27141%\n",
            "第 35 次训练迭代: train准确率 98.33159%, val准确率 77.30026%\n",
            "第 40 次训练迭代: train准确率 98.92746%, val准确率 78.33862%\n",
            "第 45 次训练迭代: train准确率 99.49352%, val准确率 79.08855%\n",
            "第 50 次训练迭代: train准确率 99.44883%, val准确率 78.51168%\n",
            "第 55 次训练迭代: train准确率 99.71697%, val准确率 79.34814%\n",
            "第 60 次训练迭代: train准确率 99.77655%, val准确率 80.06923%\n",
            "第 65 次训练迭代: train准确率 99.12111%, val准确率 78.68474%\n",
            "第 70 次训练迭代: train准确率 99.89573%, val准确率 80.96337%\n",
            "第 75 次训练迭代: train准确率 99.85104%, val准确率 79.60773%\n",
            "第 80 次训练迭代: train准确率 99.89573%, val准确率 79.92501%\n",
            "第 85 次训练迭代: train准确率 99.01683%, val准确率 76.52149%\n",
            "第 90 次训练迭代: train准确率 99.94041%, val准确率 82.14595%\n",
            "第 95 次训练迭代: train准确率 99.95531%, val准确率 82.86703%\n",
            "第 100 次训练迭代: train准确率 99.95531%, val准确率 82.46322%\n",
            "第 105 次训练迭代: train准确率 99.95531%, val准确率 81.85751%\n",
            "第 110 次训练迭代: train准确率 99.91062%, val准确率 79.20392%\n",
            "第 115 次训练迭代: train准确率 99.38924%, val准确率 78.02134%\n",
            "第 120 次训练迭代: train准确率 99.97021%, val准确率 81.51139%\n",
            "第 125 次训练迭代: train准确率 99.98510%, val准确率 82.29017%\n",
            "第 130 次训练迭代: train准确率 100.00000%, val准确率 82.14595%\n",
            "第 135 次训练迭代: train准确率 99.98510%, val准确率 82.08826%\n",
            "第 140 次训练迭代: train准确率 99.97021%, val准确率 84.04961%\n",
            "第 145 次训练迭代: train准确率 99.98510%, val准确率 83.76118%\n",
            "第 150 次训练迭代: train准确率 100.00000%, val准确率 84.13614%\n",
            "第 155 次训练迭代: train准确率 100.00000%, val准确率 83.55927%\n",
            "第 160 次训练迭代: train准确率 100.00000%, val准确率 83.64580%\n",
            "第 165 次训练迭代: train准确率 99.38924%, val准确率 81.74214%\n",
            "第 170 次训练迭代: train准确率 99.98510%, val准确率 83.53043%\n",
            "第 175 次训练迭代: train准确率 100.00000%, val准确率 83.96308%\n",
            "第 180 次训练迭代: train准确率 100.00000%, val准确率 83.44390%\n",
            "第 185 次训练迭代: train准确率 100.00000%, val准确率 83.09778%\n",
            "第 190 次训练迭代: train准确率 100.00000%, val准确率 82.52091%\n",
            "第 195 次训练迭代: train准确率 100.00000%, val准确率 83.15547%\n",
            "第 200 次训练迭代: train准确率 100.00000%, val准确率 83.27084%\n",
            "第 205 次训练迭代: train准确率 100.00000%, val准确率 82.95356%\n",
            "第 210 次训练迭代: train准确率 100.00000%, val准确率 83.73233%\n",
            "第 215 次训练迭代: train准确率 99.97021%, val准确率 80.61725%\n",
            "第 220 次训练迭代: train准确率 100.00000%, val准确率 82.34785%\n",
            "第 225 次训练迭代: train准确率 100.00000%, val准确率 82.69397%\n",
            "第 230 次训练迭代: train准确率 100.00000%, val准确率 82.69397%\n",
            "第 235 次训练迭代: train准确率 100.00000%, val准确率 82.75166%\n",
            "第 240 次训练迭代: train准确率 100.00000%, val准确率 82.72281%\n",
            "第 245 次训练迭代: train准确率 100.00000%, val准确率 83.61696%\n",
            "第 250 次训练迭代: train准确率 100.00000%, val准确率 83.18431%\n",
            "第 255 次训练迭代: train准确率 100.00000%, val准确率 82.72281%\n",
            "第 260 次训练迭代: train准确率 100.00000%, val准确率 83.61696%\n",
            "第 265 次训练迭代: train准确率 100.00000%, val准确率 82.46322%\n",
            "第 270 次训练迭代: train准确率 99.18069%, val准确率 75.71387%\n",
            "第 275 次训练迭代: train准确率 100.00000%, val准确率 81.88636%\n",
            "第 280 次训练迭代: train准确率 100.00000%, val准确率 81.94404%\n",
            "第 285 次训练迭代: train准确率 100.00000%, val准确率 82.17479%\n",
            "第 290 次训练迭代: train准确率 100.00000%, val准确率 80.27112%\n",
            "第 295 次训练迭代: train准确率 100.00000%, val准确率 81.68445%\n",
            "第 300 次训练迭代: train准确率 100.00000%, val准确率 82.23248%\n",
            "第 305 次训练迭代: train准确率 100.00000%, val准确率 82.26132%\n",
            "第 310 次训练迭代: train准确率 100.00000%, val准确率 82.08826%\n",
            "第 315 次训练迭代: train准确率 100.00000%, val准确率 82.14595%\n",
            "第 320 次训练迭代: train准确率 100.00000%, val准确率 82.69397%\n",
            "第 325 次训练迭代: train准确率 100.00000%, val准确率 82.17479%\n",
            "第 330 次训练迭代: train准确率 100.00000%, val准确率 81.94404%\n",
            "第 335 次训练迭代: train准确率 100.00000%, val准确率 81.82867%\n",
            "第 340 次训练迭代: train准确率 98.67421%, val准确率 71.18546%\n",
            "第 345 次训练迭代: train准确率 100.00000%, val准确率 81.45370%\n",
            "第 350 次训练迭代: train准确率 100.00000%, val准确率 81.45370%\n",
            "第 355 次训练迭代: train准确率 100.00000%, val准确率 81.88636%\n",
            "第 360 次训练迭代: train准确率 100.00000%, val准确率 81.36718%\n",
            "第 365 次训练迭代: train准确率 100.00000%, val准确率 81.82867%\n",
            "第 370 次训练迭代: train准确率 100.00000%, val准确率 81.39602%\n",
            "第 375 次训练迭代: train准确率 100.00000%, val准确率 81.85751%\n",
            "第 380 次训练迭代: train准确率 100.00000%, val准确率 81.54024%\n",
            "第 385 次训练迭代: train准确率 100.00000%, val准确率 81.36718%\n",
            "第 390 次训练迭代: train准确率 100.00000%, val准确率 80.32882%\n",
            "第 395 次训练迭代: train准确率 100.00000%, val准确率 82.52091%\n",
            "第 400 次训练迭代: train准确率 100.00000%, val准确率 82.14595%\n",
            "第 405 次训练迭代: train准确率 100.00000%, val准确率 82.31901%\n",
            "第 410 次训练迭代: train准确率 100.00000%, val准确率 82.26132%\n",
            "第 415 次训练迭代: train准确率 100.00000%, val准确率 82.08826%\n",
            "第 420 次训练迭代: train准确率 100.00000%, val准确率 82.40554%\n",
            "第 425 次训练迭代: train准确率 100.00000%, val准确率 82.20363%\n",
            "第 430 次训练迭代: train准确率 100.00000%, val准确率 82.46322%\n",
            "第 435 次训练迭代: train准确率 100.00000%, val准确率 82.80935%\n",
            "第 440 次训练迭代: train准确率 100.00000%, val准确率 82.49207%\n",
            "第 445 次训练迭代: train准确率 99.91062%, val准确率 81.04990%\n",
            "第 450 次训练迭代: train准确率 100.00000%, val准确率 80.32882%\n",
            "第 455 次训练迭代: train准确率 100.00000%, val准确率 80.90568%\n",
            "第 460 次训练迭代: train准确率 100.00000%, val准确率 81.51139%\n",
            "第 465 次训练迭代: train准确率 100.00000%, val准确率 82.17479%\n",
            "第 470 次训练迭代: train准确率 100.00000%, val准确率 82.23248%\n",
            "第 475 次训练迭代: train准确率 100.00000%, val准确率 82.26132%\n",
            "第 480 次训练迭代: train准确率 100.00000%, val准确率 82.46322%\n",
            "第 485 次训练迭代: train准确率 100.00000%, val准确率 82.20363%\n",
            "第 490 次训练迭代: train准确率 100.00000%, val准确率 82.46322%\n",
            "第 495 次训练迭代: train准确率 100.00000%, val准确率 82.49207%\n",
            "完成训练!\n",
            "训练耗费时间：2578秒\n",
            "不存在训练数据保存目录，现在创建保存目录\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wDibqgQ8BCu",
        "colab_type": "text"
      },
      "source": [
        "## 预测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TUP7ByX8Ap8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 读取模型checkpoint\n",
        "saver = tf.train.import_meta_graph(\"%smodel.ckpt.meta\"%(SAVER_DIR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG625ge58SV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e4d405a5-9dc5-4b3a-db12-ab7001321b54"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    model_file=tf.train.latest_checkpoint(SAVER_DIR)\n",
        "    saver.restore(sess, model_file)\n",
        "\n",
        "    # 第一个卷积层\n",
        "    W_conv1 = sess.graph.get_tensor_by_name(\"W_conv1:0\")\n",
        "    b_conv1 = sess.graph.get_tensor_by_name(\"b_conv1:0\")\n",
        "    conv_strides = [1, 1, 1, 1]\n",
        "    kernel_size = [1, 2, 2, 1]\n",
        "    pool_strides = [1, 2, 2, 1]\n",
        "    L1_pool = conv_layer(x_image, W_conv1, b_conv1, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
        "\n",
        "    # 第二个卷积层\n",
        "    W_conv2 = sess.graph.get_tensor_by_name(\"W_conv2:0\")\n",
        "    b_conv2 = sess.graph.get_tensor_by_name(\"b_conv2:0\")\n",
        "    conv_strides = [1, 1, 1, 1]\n",
        "    kernel_size = [1, 1, 1, 1]\n",
        "    pool_strides = [1, 1, 1, 1]\n",
        "    L2_pool = conv_layer(L1_pool, W_conv2, b_conv2, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
        "\n",
        "\n",
        "    # 全连接层\n",
        "    W_fc1 = sess.graph.get_tensor_by_name(\"W_fc1:0\")\n",
        "    b_fc1 = sess.graph.get_tensor_by_name(\"b_fc1:0\")\n",
        "    h_pool2_flat = tf.reshape(L2_pool, [-1, 10 * 10 * 32])\n",
        "    h_fc1 = full_connect(h_pool2_flat, W_fc1, b_fc1)\n",
        "\n",
        "\n",
        "    # dropout\n",
        "    keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "\n",
        "\n",
        "    # readout层\n",
        "    W_fc2 = sess.graph.get_tensor_by_name(\"W_fc2:0\")\n",
        "    b_fc2 = sess.graph.get_tensor_by_name(\"b_fc2:0\")\n",
        "\n",
        "    # 定义优化器和训练op\n",
        "    conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
        "\n",
        "    for n in range(1, 2):\n",
        "        path = r'/content/gdrive/My Drive/mylab/Exp2/dataset/b.bmp'\n",
        "        img = Image.open(path)\n",
        "        img = img.resize((20,20))\n",
        "        width = img.size[0]\n",
        "        height = img.size[1]\n",
        "\n",
        "        img_data = np.array([[0]*SIZE for i in range(1)])\n",
        "        for h in range(0, height):\n",
        "            for w in range(0, width):\n",
        "                img_data[0][w+h*width] = img.getpixel((w,h))\n",
        "\n",
        "        img = img_data.astype('float32')/255\n",
        "\n",
        "        result = sess.run(conv, feed_dict = {x: img, keep_prob: 1.0})\n",
        "\n",
        "        max1 = 0\n",
        "        max2 = 0\n",
        "        max3 = 0\n",
        "        max1_index = 0\n",
        "        max2_index = 0\n",
        "        max3_index = 0\n",
        "        for j in range(NUM_CLASSES):\n",
        "            if result[0][j] > max1:\n",
        "                max1 = result[0][j]\n",
        "                max1_index = j\n",
        "                continue\n",
        "            if (result[0][j]>max2) and (result[0][j]<=max1):\n",
        "                max2 = result[0][j]\n",
        "                max2_index = j\n",
        "                continue\n",
        "            if (result[0][j]>max3) and (result[0][j]<=max2):\n",
        "                max3 = result[0][j]\n",
        "                max3_index = j\n",
        "                continue\n",
        "\n",
        "        if n == 3:\n",
        "            license_num += \"-\"\n",
        "        license_num = license_num + LETTERS_DIGITS[max1_index]\n",
        "        print (\"概率：  [%s %0.2f%%]    [%s %0.2f%%]    [%s %0.2f%%]\" % (LETTERS_DIGITS[max1_index],max1*100, LETTERS_DIGITS[max2_index],max2*100, LETTERS_DIGITS[max3_index],max3*100))\n",
        "\n",
        "    print (\"城市代号是: 【%s】\" % license_num)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/mylab/Exp2/train-saver/letters/model.ckpt\n",
            "概率：  [E 84.31%]    [R 15.65%]    [P 0.00%]\n",
            "城市代号是: 【E】\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouSRg7u69TJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2c47eda3-9ec2-427c-90ff-1a39da43c870"
      },
      "source": [
        "license_num = ''\n",
        "with tf.Session() as sess:\n",
        "    model_file=tf.train.latest_checkpoint(SAVER_DIR)\n",
        "    saver.restore(sess, model_file)\n",
        "\n",
        "    # 第一个卷积层\n",
        "    W_conv1 = sess.graph.get_tensor_by_name(\"W_conv1:0\")\n",
        "    b_conv1 = sess.graph.get_tensor_by_name(\"b_conv1:0\")\n",
        "    conv_strides = [1, 1, 1, 1]\n",
        "    kernel_size = [1, 2, 2, 1]\n",
        "    pool_strides = [1, 2, 2, 1]\n",
        "    L1_pool = conv_layer(x_image, W_conv1, b_conv1, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
        "\n",
        "    # 第二个卷积层\n",
        "    W_conv2 = sess.graph.get_tensor_by_name(\"W_conv2:0\")\n",
        "    b_conv2 = sess.graph.get_tensor_by_name(\"b_conv2:0\")\n",
        "    conv_strides = [1, 1, 1, 1]\n",
        "    kernel_size = [1, 1, 1, 1]\n",
        "    pool_strides = [1, 1, 1, 1]\n",
        "    L2_pool = conv_layer(L1_pool, W_conv2, b_conv2, conv_strides, kernel_size, pool_strides, padding='SAME')\n",
        "\n",
        "\n",
        "    # 全连接层\n",
        "    W_fc1 = sess.graph.get_tensor_by_name(\"W_fc1:0\")\n",
        "    b_fc1 = sess.graph.get_tensor_by_name(\"b_fc1:0\")\n",
        "    h_pool2_flat = tf.reshape(L2_pool, [-1, 10 * 10 * 32])\n",
        "    h_fc1 = full_connect(h_pool2_flat, W_fc1, b_fc1)\n",
        "\n",
        "\n",
        "    # dropout\n",
        "    keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "\n",
        "\n",
        "    # readout层\n",
        "    W_fc2 = sess.graph.get_tensor_by_name(\"W_fc2:0\")\n",
        "    b_fc2 = sess.graph.get_tensor_by_name(\"b_fc2:0\")\n",
        "\n",
        "    # 定义优化器和训练op\n",
        "    conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
        "\n",
        "    for n in range(1, 2):\n",
        "        path = r'/content/gdrive/My Drive/mylab/Exp2/dataset/j.bmp'\n",
        "        img = Image.open(path)\n",
        "        img = img.resize((20,20))\n",
        "        width = img.size[0]\n",
        "        height = img.size[1]\n",
        "\n",
        "        img_data = np.array([[0]*SIZE for i in range(1)])\n",
        "        for h in range(0, height):\n",
        "            for w in range(0, width):\n",
        "                img_data[0][w+h*width] = img.getpixel((w,h))\n",
        "\n",
        "        img = img_data.astype('float32')/255\n",
        "\n",
        "        result = sess.run(conv, feed_dict = {x: img, keep_prob: 1.0})\n",
        "\n",
        "        max1 = 0\n",
        "        max2 = 0\n",
        "        max3 = 0\n",
        "        max1_index = 0\n",
        "        max2_index = 0\n",
        "        max3_index = 0\n",
        "        for j in range(NUM_CLASSES):\n",
        "            if result[0][j] > max1:\n",
        "                max1 = result[0][j]\n",
        "                max1_index = j\n",
        "                continue\n",
        "            if (result[0][j]>max2) and (result[0][j]<=max1):\n",
        "                max2 = result[0][j]\n",
        "                max2_index = j\n",
        "                continue\n",
        "            if (result[0][j]>max3) and (result[0][j]<=max2):\n",
        "                max3 = result[0][j]\n",
        "                max3_index = j\n",
        "                continue\n",
        "\n",
        "        if n == 3:\n",
        "            license_num += \"-\"\n",
        "        license_num = license_num + LETTERS_DIGITS[max1_index]\n",
        "        print (\"概率：  [%s %0.2f%%]    [%s %0.2f%%]    [%s %0.2f%%]\" % (LETTERS_DIGITS[max1_index],max1*100, LETTERS_DIGITS[max2_index],max2*100, LETTERS_DIGITS[max3_index],max3*100))\n",
        "\n",
        "    print (\"城市代号是: 【%s】\" % license_num)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/mylab/Exp2/train-saver/letters/model.ckpt\n",
            "概率：  [J 100.00%]    [O 0.00%]    [U 0.00%]\n",
            "城市代号是: 【J】\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}